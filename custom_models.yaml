Fireworks:
  Api_Interface: OpenAI
  Max_Tokens_Arg_Name: max_tokens
  Token_Window: 128000
  Client_Args:
    base_url: https://api.fireworks.ai/inference/v1
  models:
    fw-llama-v3p2-1b-instruct: {}
    fw-llama-v3p2-3b-instruct: {}
    fw-llama-v3p2-11b-vision-instruct:
      Api_Model_Name: accounts/fireworks/models/llama-v3p2-11b-vision-instruct
      Vision: True
      Token_Window: 131072
    fw-llama-v3p2-90b-vision-instruct:
      Api_Model_Name: accounts/fireworks/models/llama-v3p2-90b-vision-instruct
      Vision: True
      Token_Window: 131072
      Tool_Use: True
    fw-llama-v3p1-8b-instruct:
      Api_Model_Name: accounts/fireworks/models/llama-v3p1-8b-instruct
    fw-llama-v3p1-70b-instruct: {}
    fw-llama-v3p1-405b-instruct:
      Tool_Use: True
    fw-qwen2p5-72b: {}
    fw-qwen2p5-72b-instruct:
      Tool_Use: True
    fw-qwen2p5-7b-instruct:
      Api_Model_Name: accounts/fireworks/models/qwen2p5-7b-instruct#accounts/robince-fd38a7/deployments/57979474
      Token_Window: 131072
      Token_Limit_Completion: 8192
    fw-qwen2p5-14b-instruct:
      Api_Model_Name: accounts/fireworks/models/qwen2p5-14b-instruct#accounts/robince-fd38a7/deployments/7255839c
      Token_Window: 131072
      Token_Limit_Completion: 8192
    fw-qwen2p5-32b-instruct:
      Api_Model_Name: accounts/fireworks/models/qwen2p5-32b-instruct#accounts/robince-fd38a7/deployments/3b49b4cf
      Token_Window: 131072
      Token_Limit_Completion: 8192
    fw-mixtral-8x22b-instruct: {}
    fw-mixtral-8x7b-instruct: {}
    fw-mixtral-8x7b-instruct-hf: {}
    fw-yi-large: {}
    fw-firefunction-v2:
      Api_Model_Name: accounts/fireworks/models/firefunction-v2
      Token_Window: 32768
      Tool_Use: True
    fw-phi-3-vision-128k-instruct:
      Api_Model_Name: accounts/fireworks/models/phi-3-vision-128k-instruct
      Token_Window: 128000
    fw-calmerys-78b-orpo-v0p1:
      Api_Model_Name: accounts/robince-fd38a7/models/calmerys-78b-orpo-v0p1#accounts/robince-fd38a7/deployments/44e3e3af
      Token_Window: 131072
      Token_Limit_Completion: 32768
    fw-llama-3p1-nemotron-70b-instruct-hf:
      Api_Model_Name: accounts/robince-fd38a7/models/llama-3p1-nemotron-70b-instruct-hf#accounts/robince-fd38a7/deployments/c0d26423
      Token_Window: 131072
      Token_Limit_Completion: 32768
    fw-mistral-nemo-instruct-2407:
      Api_Model_Name: accounts/fireworks/models/mistral-nemo-instruct-2407#accounts/robince-fd38a7/deployments/429f83fb
      Token_Window: 128000
    fw-qwq-32b-preview:
      Api_Model_Name: accounts/robince-fd38a7/models/qwq-ri2#accounts/robince-fd38a7/deployments/b7f8cb46
      Token_Window: 32768
    fw-llama-v3p3-70b-instruct:
      Api_Model_Name: accounts/fireworks/models/llama-v3p3-70b-instruct
    fw-llama-v2-7b:
      Api_Model_Name: accounts/fireworks/models/llama-v2-7b#accounts/robince-fd38a7/deployments/077376d4
      Token_Window: 4096
    fw-llama-v2-13b:
      Api_Model_Name: accounts/fireworks/models/llama-v2-13b#accounts/robince-fd38a7/deployments/e0ea333c
      Token_Window: 4096
    fw-llama-v2-70b:
      Api_Model_Name: accounts/fireworks/models/llama-v2-70b#accounts/robince-fd38a7/deployments/1874ceae
      Token_Window: 4096
    fw-llama-v2-7b-chat:
      Api_Model_Name: accounts/fireworks/models/llama-v2-7b-chat#accounts/robince-fd38a7/deployments/46b708cd
      Token_Window: 4096
    fw-llama-v2-13b-chat:
      Api_Model_Name: accounts/fireworks/models/llama-v2-13b-chat#accounts/robince-fd38a7/deployments/692f6c27
      Token_Window: 4096
    fw-llama-v2-70b-chat:
      Api_Model_Name: accounts/fireworks/models/llama-v2-70b-chat#accounts/robince-fd38a7/deployments/936e9f16
      Token_Window: 4096
    fw-gemma2-9b-it:
      Api_Model_Name: accounts/fireworks/models/gemma2-9b-it
      Token_Window: 8000
    fw-deepseek-v2p5:
      Api_Model_Name: accounts/fireworks/models/deepseek-v2p5#accounts/robince-fd38a7/deployments/723bc292
      Token_Window: 66000
      Token_Limit_Completion: 8000
    fw-deepseek-v3:
      Api_Model_Name: accounts/fireworks/models/deepseek-v3
      Token_Window: 128000
      Token_Limit_Completion: 8000
    fw-deepseek-r1:
      Api_Model_Name: accounts/fireworks/models/deepseek-r1
      Token_Window: 64000
      Token_Limit_Completion: 8000
    fw-mistral-small-3-instruct:
      Api_Model_Name: accounts/fireworks/models/mistral-small-24b-instruct-2501
      Token_Window: 32000
      Token_Limit_Completion: 4000
    fw-deepseek-r1-wo-fs:
      Api_Model_Name: accounts/fireworks/models/deepseek-r1
      Token_Window: 64000
      Token_Limit_Completion: 8000
    llama-4-maverick-instruct-basic:
      Api_Model_Name: accounts/fireworks/models/llama4-maverick-instruct-basic
      Token_Window: 1050000
      Token_Limit_Completion: 4000
    llama-4-scout-instruct-basic:
      Api_Model_Name: accounts/fireworks/models/llama4-scout-instruct-basic
      Token_Window: 131000
      Token_Limit_Completion: 4000
    qwen-3-30b-a3b:
      Api_Model_Name: accounts/fireworks/models/qwen3-30b-a3b
      Token_Window: 41000
      Token_Limit_Completion: 4000
    qwen-3-235b-a22b:
      Api_Model_Name: accounts/fireworks/models/qwen3-235b-a22b
      Token_Window: 41000
      Token_Limit_Completion: 4000
    fw-deepseek-r1-0528:
      Api_Model_Name: accounts/fireworks/models/deepseek-r1-0528
      Token_Window: 160000
      Token_Limit_Completion: 20480

LingYiWanWu:
  Api_Interface: OpenAI
  Api_Key_Env_Var: LINGYIWANWU_API_KEY
  Client_Args:
    base_url: https://api.lingyiwanwu.com/v1
  models:
    yi-lightning:
      Token_Window: 16000
    yi-large-fc:
      Token_Window: 32000
      Tool_Use: True

Scaleway:
  Api_Interface: OpenAI
  Api_Key_Env_Var: SCALEWAY_API_KEY
  Client_Args:
    base_url: https://api.scaleway.ai/v1
  models:
    sw-mistral-nemo-instruct-2407:
      Api_Model_Name: mistral-nemo-instruct-2407
      Token_Window: 128000

Tencent:
  Api_Interface: OpenAI
  Api_Key_Env_Var: TENCENT_API_KEY
  Client_Args:
    base_url: https://api.hunyuan.cloud.tencent.com/v1
  models:
    hunyuan-large:
      Api_Model_Name: hunyuan-large
      Token_Window: 28000
      Token_Limit_Completion: 4000
    hunyuan-large-longcontext:
      Api_Model_Name: hunyuan-large-longcontext
      Token_Window: 128000
      Token_Limit_Completion: 6000
    hunyuan-a13b:
      Api_Model_Name: hunyuan-a13b
      Token_Window: 224000
      Token_Limit_Completion: 32000

OpenRouter:
  Api_Interface: OpenAI
  Api_Key_Env_Var: OPENROUTER_API_KEY
  Client_Args:
    base_url: https://openrouter.ai/api/v1
  models:
    command-r-plus:
      Token_Window: 128000
      Token_Limit_Completion: 4000
      Api_Model_Name: cohere/command-r-plus-08-2024
    grok-beta:
      Token_Window: 131072
      Token_Limit_Completion: 4000
      Api_Model_Name: x-ai/grok-beta
    jamba-1-5-large:
      Token_Window: 256000
      Token_Limit_Completion: 4000
      Api_Model_Name: ai21/jamba-1-5-large
    jamba-1-5-mini:
      Token_Window: 256000
      Token_Limit_Completion: 4000
      Api_Model_Name: ai21/jamba-1-5-mini
    jamba-instruct:
      Token_Window: 256000
      Token_Limit_Completion: 4000
      Api_Model_Name: ai21/jamba-instruct
    gemini-exp-1206-free:
      Token_Window: 8192
      Token_Limit_Completion: 8192
      Api_Model_Name: google/gemini-exp-1206:free
    gemma-2-27b-it:
      Token_Window: 8192
      Token_Limit_Completion: 8192
      Api_Model_Name: google/gemma-2-27b-it
    grok-2-1212:
      Token_Window: 131072
      Token_Limit_Completion: 4000
      Api_Model_Name: x-ai/grok-2-1212
    cohere-r7b-1224:
      Token_Window: 128000
      Token_Limit_Completion: 4000
      Api_Model_Name: cohere/command-r7b-12-2024
    mistral-large-2411:
      Token_Window: 128000
      Token_Limit_Completion: 4096
      Api_Model_Name: mistralai/mistral-large-2411
    ministral-8b:
      Token_Window: 128000
      Token_Limit_Completion: 4096
      Api_Model_Name: mistralai/ministral-8b
    ministral-3b:
      Token_Window: 128000
      Token_Limit_Completion: 4096
      Api_Model_Name: mistralai/ministral-3b
    qwen-qvq-72b-preview:
      Token_Window: 128000
      Token_Limit_Completion: 4000
      Api_Model_Name: qwen/qvq-72b-preview
    microsoft-phi-4-bf16:
      Token_Window: 16000
      Token_Limit_Completion: 4000
      Api_Model_Name: microsoft/phi-4
    deepseek-r1:
      Token_Window: 64000
      Token_Limit_Completion: 4000
      Api_Model_Name: deepseek/deepseek-r1
      Client_Args:
        extra_body:
          provider:
            order:
              - Deepseek
            allow_fallbacks: False
    liquid-lfm-7b:
      Token_Window: 33000
      Token_Limit_Completion: 4000
      Api_Model_Name: liquid/lfm-7b
    deepseek-r1-nvt:
      Token_Window: 64000
      Token_Limit_Completion: 4000
      Api_Model_Name: deepseek/deepseek-r1
      Client_Args:
        extra_body:
          provider:
            order:
              - NovitaAI
            allow_fallbacks: False
    sonar:
      Token_Window: 127000
      Token_Limit_Completion: 4000
      Api_Model_Name: perplexity/sonar
    sonar-reasoning:
      Token_Window: 127000
      Token_Limit_Completion: 4000
      Api_Model_Name: perplexity/sonar-reasoning
    qwen-qwq-32b:
      Token_Window: 131000
      Token_Limit_Completion: 4000
      Api_Model_Name: qwen/qwq-32b
      Client_Args:
        extra_body:
          provider:
            order:
              - DeepInfra
            allow_fallbacks: False
    liquid-lfm-3b:
      Token_Window: 33000
      Token_Limit_Completion: 4000
      Api_Model_Name: liquid/lfm-3b
    phi-4-multimodal-instruct-bf16:
      Token_Window: 131000
      Token_Limit_Completion: 4000
      Api_Model_Name: microsoft/phi-4-multimodal-instruct
    phi-35-mini:
      Token_Window: 128000
      Token_Limit_Completion: 4000
      Api_Model_Name: microsoft/phi-3.5-mini-128k-instruct
    cohere-command-a:
      Token_Window: 256000
      Token_Limit_Completion: 8000
      Api_Model_Name: cohere/command-a
    jamba-1-6-large:
      Token_Window: 256000
      Token_Limit_Completion: 4000
      Api_Model_Name: ai21/jamba-1.6-large
    jamba-1-6-mini:
      Token_Window: 256000
      Token_Limit_Completion: 4000
      Api_Model_Name: ai21/jamba-1.6-mini
    gemma-3-27b:
      Token_Window: 128000
      Token_Limit_Completion: 8192
      Api_Model_Name: google/gemma-3-27b-it
      Client_Args:
        extra_body:
          provider:
            order:
              - Parasail
            allow_fallbacks: False
    olmo-2-32b:
      Token_Window: 4000
      Token_Limit_Completion: 4000
      Api_Model_Name: allenai/olmo-2-0325-32b-instruct
      Client_Args:
        extra_body:
          provider:
            order:
              - Parasail
            allow_fallbacks: False
    mistral-small-3-1-24b:
      Token_Window: 128000
      Token_Limit_Completion: 4000
      Api_Model_Name: mistralai/mistral-small-3.1-24b-instruct-2503
      Client_Args:
        extra_body:
          provider:
            order:
              - Mistral
            allow_fallbacks: False
    deepseek-v3-0324-fp8:
      Token_Window: 66000
      Token_Limit_Completion: 4000
      Api_Model_Name: deepseek/deepseek-chat-v3-0324
      Client_Args:
        extra_body:
          provider:
            order:
              - DeepInfra
            allow_fallbacks: False
    gemma-3-12b-it:
      Token_Window: 131000
      Token_Limit_Completion: 8192
      Api_Model_Name: google/gemma-3-12b-it
    gemma-3-4b-it:
      Token_Window: 131000
      Token_Limit_Completion: 8192
      Api_Model_Name: google/gemma-3-4b-it
    grok-3-beta:
      Token_Window: 131000
      Token_Limit_Completion: 4000
      Api_Model_Name: x-ai/grok-3-beta
      Client_Args:
        extra_body:
          provider:
            order:
              - xAI
            allow_fallbacks: False
    grok-3-mini-beta:
      Token_Window: 131000
      Token_Limit_Completion: 4000
      Api_Model_Name: x-ai/grok-3-mini-beta
      Client_Args:
        extra_body:
          provider:
            order:
              - xAI
            allow_fallbacks: False
    qwen-3-32b:
      Token_Window: 41000
      Token_Limit_Completion: 4000
      Api_Model_Name: qwen/qwen3-32b
      Client_Args:
        extra_body:
          provider:
            order:
              - DeepInfra
            allow_fallbacks: False
    qwen-3-14b:
      Token_Window: 41000
      Token_Limit_Completion: 4000
      Api_Model_Name: qwen/qwen3-14b
      Client_Args:
        extra_body:
          provider:
            order:
              - DeepInfra
            allow_fallbacks: False
    phi-4-reasoning-plus:
      Token_Window: 33000
      Token_Limit_Completion: 4000
      Api_Model_Name: microsoft/phi-4-reasoning-plus
    mistral-medium-3:
      Token_Window: 131000
      Token_Limit_Completion: 4000
      Api_Model_Name: mistralai/mistral-medium-3
    deepseek-r1-0528-fp8-lambda:
      Token_Window: 160000
      Token_Limit_Completion: 20480
      Api_Model_Name: deepseek/deepseek-r1-0528
      Client_Args:
        extra_body:
          provider:
            order:
              - Lambda
            allow_fallbacks: False
    qwen-3-8b-fp8:
      Token_Window: 128000
      Token_Limit_Completion: 20000
      Api_Model_Name: qwen/qwen3-8b
      Client_Args:
        extra_body:
          provider:
            order:
              - DeepInfra
            allow_fallbacks: False
    magistral-small-2506:
      Token_Window: 40000
      Token_Limit_Completion: 4000
      Api_Model_Name: mistralai/magistral-small-2506
    magistral-medium-2506:
      Token_Window: 40000
      Token_Limit_Completion: 4000
      Api_Model_Name: mistralai/magistral-medium-2506
    llama-v3p2-1b-instruct-bf16:
      Token_Window: 131000
      Token_Limit_Completion: 16000
      Api_Model_Name: meta-llama/llama-3.2-1b-instruct
    llama-v3p2-3b-instruct-bf16:
      Token_Window: 131000
      Token_Limit_Completion: 16000
      Api_Model_Name: meta-llama/llama-3.2-3b-instruct
    mistral-nemo-instruct-2407-fp8:
      Token_Window: 131000
      Token_Limit_Completion: 16000
      Api_Model_Name: mistralai/mistral-nemo
    qwen-2p5-7b-instruct-bf16:
      Token_Window: 33000
      Token_Limit_Completion: 16000
      Api_Model_Name: qwen/qwen-2.5-7b-instruct
    mistral-small-24b-instruct-2501-fp8:
      Token_Window: 32000
      Token_Limit_Completion: 16000
      Api_Model_Name: mistralai/mistral-small-24b-instruct-2501
    minimax-m1:
      Token_Window: 1000000
      Token_Limit_Completion: 40000
      Api_Model_Name: minimax/minimax-m1

AmazonBedrock:
  Api_Interface: Bedrock
  Api_Key_Env_Var: BEDROCK_API_KEY
  Client_Args:
    region_name: us-east-1
  Token_Window: 300000
  Vision: True
  models:
    amazon-nova-pro-v1:
      Token_Limit_Completion: 5000
      Api_Model_Name: "amazon.nova-pro-v1:0"
    amazon-nova-lite-v1: 
      Token_Limit_Completion: 5000
      Api_Model_Name: "amazon.nova-lite-v1:0"
    amazon-nova-micro-v1:
      Vision: False
      Token_Window: 128000
      Token_Limit_Completion: 5000
      Api_Model_Name: "amazon.nova-micro-v1:0"

Google:
  Api_Interface: GoogleGenAI
  Max_Token_Arg_Name: max_output_tokens
  Api_Key_Env_Var: GEMINI_API_KEY
  models:
    gemini-2.0-flash:
      Api_Model_Name: models/gemini-2.0-flash
      Vision: False
      Token_Window: 1048576
      Token_Limit_Completion: 8192
    gemini-2.0-pro-exp:
      Api_Model_Name: models/gemini-2.0-pro-exp-02-05
      Vision: False
      Token_Window: 1048576
      Token_Limit_Completion: 8192
    gemini-2.0-flash-thinking-exp:
      Api_Model_Name: models/gemini-2.0-flash-thinking-exp-01-21
      Vision: False
      Token_Window: 1048576
      Token_Limit_Completion: 8192
    gemini-2.0-flash-lite:
      Api_Model_Name: models/gemini-2.0-flash-lite
      Vision: False
      Token_Window: 1048576
      Token_Limit_Completion: 8192
    gemini-1.5-flash-001:
      Api_Model_Name: models/gemini-1.5-flash
      Vision: False
      Token_Window: 1048576
      Token_Limit_Completion: 8192
    gemini-1.5-pro-001:
      Api_Model_Name: models/gemini-1.5-pro
      Vision: False
      Token_Window: 1048576
      Token_Limit_Completion: 8192
    gemini-1.5-flash-8b:
      Api_Model_Name: models/gemini-1.5-flash-8b
      Vision: False
      Token_Window: 1048576
      Token_Limit_Completion: 8192
    gemini-2.5-pro-exp-03-25:
      Vision: True
      Tool_Use: True
      Token_Window: 1000000
      Token_Limit_Completion: 64000
    gemini-2.5-flash-preview-04-17:
      Api_Model_Name: models/gemini-2.5-flash-preview-04-17
      Vision: True
      Token_Window: 1048576
      Token_Limit_Completion: 65536
    gemini-2.5-pro-preview-05-06:
      Api_Model_Name: models/gemini-2.5-pro-preview-05-06
      Vision: True
      Token_Window: 1048576
      Token_Limit_Completion: 65536
    gemini-2.5-flash-preview-05-20:
      Api_Model_Name: models/gemini-2.5-flash-preview-05-20
      Vision: True
      Token_Window: 1048576
      Token_Limit_Completion: 65536
    gemma-3n-e4b-it:
      Api_Model_Name: models/gemma-3n-e4b-it
      Vision: True
      Token_Window: 131000
      Token_Limit_Completion: 8192
    learnlm-2.0-flash-experimental:
      Api_Model_Name: models/learnlm-2.0-flash-experimental
      Vision: True
      Token_Window: 1048576
      Token_Limit_Completion: 8192
    gemini-2.5-pro-preview-06-05:
      Api_Model_Name: models/gemini-2.5-pro-preview-06-05
      Vision: True
      Token_Window: 1048576
      Token_Limit_Completion: 65536
    gemini-2.5-flash-lite-preview-06-17:
      Api_Model_Name: models/gemini-2.5-flash-lite-preview-06-17
      Vision: True
      Token_Window: 1000000
      Token_Limit_Completion: 64000

OpenAIBenchmarks:
  Api_Interface: OpenAI
  Token_Window: 200000
  Token_Limit_Completion: 100000
  Tool_Use: True
  Vision: True
  models:
    o3-mini-low:
      Api_Model_Name: o3-mini-2025-01-31
    o3-mini-medium:
      Api_Model_Name: o3-mini-2025-01-31
    o3-mini-high:
      Api_Model_Name: o3-mini-2025-01-31
    gpt-4.5-preview:
      Api_Model_Name: gpt-4.5-preview-2025-02-27
      Token_Window: 16384
    gpt-4.1:
      Api_Model_Name: gpt-4.1-2025-04-14
      Token_Window: 32768
    gpt-4.1-mini:
      Api_Model_Name: gpt-4.1-mini-2025-04-14
      Token_Window: 32768
    gpt-4.1-nano:
      Api_Model_Name: gpt-4.1-nano-2025-04-14
      Token_Window: 32768
    o4-mini-2025-04-16:
      Api_Model_Name: o4-mini-2025-04-16
      Token_Window: 100000
    o3-2025-04-16:
      Api_Model_Name: o3-2025-04-16
      Token_Window: 100000
    

ByteDance:
  Api_Interface: OpenAI
  Api_Key_Env_Var: BYTEDANCE_API_KEY
  Client_Args:
    base_url: https://ark.cn-beijing.volces.com/api/v3
  models:
    doubao-1.5-pro-32k:
      Api_Model_Name: ep-20250203223423-6wx9r
      Token_Window: 32000
      Token_Limit_Completion: 12000
    doubao-1.5-lite-32k:
      Api_Model_Name: ep-20250203223540-htwxr
      Token_Window: 32000
      Token_Limit_Completion: 12000
    doubao-1.5-pro-256k:
      Api_Model_Name: ep-20250203223600-vsmj5
      Token_Window: 256000
      Token_Limit_Completion: 12000

Anthropic:
  Api_Interface: Anthropic
  Max_Token_Arg_Name: max_tokens
  Flexible_SysMsg: False
  Token_Window: 200000
  Tool_Use: True
  Vision: True
  models:
    claude-3-7-sonnet-latest:
      Token_Limit_Completion: 8192
    claude-3-7-sonnet-20250219:
      Token_Limit_Completion: 8192

Anthropic_Thinking:
  Api_Interface: AnthropicStreaming
  Max_Token_Arg_Name: max_tokens
  Flexible_SysMsg: False
  Token_Window: 200000
  Token_Limit_Completion: 128000
  Tool_Use: False
  Vision: True
  models:
    claude-3-7-sonnet-20250219-thinking-high:
      Api_Model_Name: claude-3-7-sonnet-20250219
      Call_Args:
        betas: ["output-128k-2025-02-19"]
        thinking:
          type: enabled
          budget_tokens: 64000
    claude-3-7-sonnet-20250219-thinking-medium:
      Api_Model_Name: claude-3-7-sonnet-20250219
      Call_Args:
        betas: ["output-128k-2025-02-19"]
        thinking:
          type: enabled
          budget_tokens: 32000
    claude-3-7-sonnet-20250219-thinking-low:
      Api_Model_Name: claude-3-7-sonnet-20250219
      Call_Args:
        betas: ["output-128k-2025-02-19"]
        thinking:
          type: enabled
          budget_tokens: 16000
    claude-opus-4-20250514:
      Token_Limit_Completion: 32000
    claude-sonnet-4-20250514:
      Token_Limit_Completion: 64000
    claude-sonnet-4-20250514-low:
      Api_Model_Name: claude-sonnet-4-20250514
      Token_Limit_Completion: 64000
      Call_Args:
        thinking:
          type: enabled
          budget_tokens: 16000
    claude-opus-4-20250514-low:
      Api_Model_Name: claude-opus-4-20250514
      Token_Limit_Completion: 32000
      Call_Args:
        thinking:
          type: enabled
          budget_tokens: 16000